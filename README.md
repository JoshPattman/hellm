# HeLLM: The Language You Never Knew You Didn't Need ğŸ¤¯ğŸ’€

Are you tired of your programming language being far too good? ğŸ˜´ Do you find yourself frustrated by fast runtimes, reliable output, and helpful type systems? ğŸ˜¤ Introducing **HeLLM** ğŸ‰ â€“ the only language where *every single statement* is passed through a Large Language Model before it even thinks about running! ğŸ¤–âœ¨ Why settle for deterministic, logical execution when you could have the full creative chaos of an LLM at your fingertips? ğŸ¨ğŸ”¥

## Features ğŸŒŸ

- **LLM-Powered Everything** ğŸš€ğŸ¤–  
  Every line, every variable, every print statement â€“ all interpreted by a Large Language Model! ğŸ“âš¡ Who needs compilers when you have vibes? âœ¨ğŸ­

- **Revolutionary Function System** ğŸ”§âš™ï¸  
  Define functions with `fn` and call them with `run`! ğŸƒâ€â™‚ï¸ğŸ’¨ Because why use normal function calls when you can confuse everyone with custom syntax? ğŸ˜µâ€ğŸ’« Functions even support multiple return values, although only as args as kwargs are far too readable! ğŸ“šâŒ

- **Pay-as-you-go Interpretation** ğŸ’¸ğŸ’³  
  HeLLM doesn't just interpret your code â€“ it consults an LLM for every single step, ensuring maximum latency and minimum predictability! â°ğŸ²

- **Nondeterministic Output** ğŸ°ğŸ¯  
  Since every statement is filtered through an LLM, you never know what you'll get! ğŸ¤·â€â™‚ï¸ Your code might work, or it might write poetry. ğŸ“–âœ¨ Isn't that exciting? ğŸŠ

- **No Pesky Types** ğŸš«ğŸ“Š  
  Types are for the weak! ğŸ’ª In HeLLM, the LLM decides what your variables mean, and sometimes it changes its mind. ğŸ§ ğŸ’­ Function parameters? Just vibes. âœ¨ğŸŒˆ

- **Blazingly Slow** ğŸŒâš¡  
  Why rush? ğŸ¤” With every statement sent to an LLM, HeLLM ensures you have plenty of time to reflect on your life choices while waiting for your code to finish! â³ğŸ˜…

- **Expressive Syntax** ğŸ­ğŸ“  
  Write code that looks almost like English, but not quite enough to be understandable! ğŸ¤ª The LLM will figure it out. Or not. ğŸ¤–â“

- **All the Operators You Need!** âš¡ğŸ”§  
  HeLLM gives you the essentials: `if`, variable assignment, `while` loops, reading input from the CLI, printing to stdout, function definitions with `fn`, function calls with `run`, and even `return` statements! ğŸ¯âœ… All other operators are useless (trust me, ChatGPT says so, bro). ğŸ¤–ğŸ’¬


## Example ğŸ“ğŸ’¡

```hellm

com "This is a comment, this is ommitted when interpreting";

com "Count to 5, printing each number";
let x = "0";
while "Is x < 5?" {
    let x = "Calculate x + 1";
    print x;
}

com "Query general knowledge";
let city = "The captial city of the UK";
print city;

com "Get the first command line arg";
use name = 0;

com "Define functions and run them from each other";

fn generate_greeting name {
    let greeting = "A greeting for the person called <name>";
    return greeting;
}


fn greet name {
    run msg = generate_greeting name;
    print msg;
}


com "Greet the name, then delete the name from the scope (so no more llm calls see it)";
run greet name;
del name;

com "Use conditional logic, with optional else blocks, and scoping";
let msg = "Empty string";
if "<city> is in europe" {
    let msg = "Exact text: Your city is in europe";
} else {
    let msg = "Exact text: Your city is not in europe";
}
print msg;
```

## Extra Features â­ğŸ
- **VSCode Extension Available** ğŸ’»ğŸ”Œ  
  Enjoy first-class HeLLM support in Visual Studio Code: ğŸ‰
  - Syntax highlighting for all your HeLLM masterpieces. ğŸ¨âœ¨
  - Document formatting to keep your code looking sharp (but beware: extra whitespace is strictly forbidden â€” this isn't Python, after all). ğŸ“ğŸš«
  - Instant feedback as you type, so you can focus on creative chaos, not code style. âš¡ğŸ­

## Installation ğŸ› ï¸ğŸ“¦

Follow these steps to get HeLLM up and running: ğŸƒâ€â™‚ï¸ğŸ’¨

### Step 1: Set Your OpenAI API Key ğŸ”‘ğŸŒ

HeLLM needs access to an OpenAI API key. ğŸ¤– Set your `OPENAI_KEY` environment variable in your shell: ğŸ’»
```
export OPENAI_KEY=sk-...
```
(Replace `sk-...` with your actual OpenAI API key, so you can track how much money you are ~~wasting~~ enjoying.) ğŸ’¸ğŸ˜„

### Step 2: Get the HeLLM Binary ğŸ“¦ğŸ’¾

Choose one of the following methods:

#### Option A: Download Pre-built Binary (Recommended) ğŸ“¥âš¡

The easiest way â€“ no compilation required! ğŸ‰

1. **Download the Binary** ğŸŒ  
   Head to the [releases page](https://github.com/JoshPattman/hellm/releases) and download the appropriate binary for your system:
   - **Linux**: `hellm-linux`
   - **macOS**: `hellm-mac` 
   - **Windows**: `hellm-windows.exe`

2. **Make Executable & Install** (Linux/Mac only) ğŸ”§  
   ```
   chmod +x hellm-linux  # or hellm-mac
   sudo mv hellm-linux /usr/local/bin/hellm  # Linux
   sudo mv hellm-mac /usr/local/bin/hellm    # macOS
   ```
   > For windows users, ask ChatGPT how to do this.

#### Option B: Build from Source ğŸ”¨âš™ï¸

For the brave souls who want to compile everything themselves: ğŸ’ª

1. **Prerequisites** ğŸ§ğŸ’»  
   - Be on Unix (sorry Windows users â€“ makefile only works on Unix-like systems ğŸ˜¢)
   - Install Go (Golang) ğŸ¹âš¡ If you don't know how, I'm sure ChatGPT can help. ğŸ¤–ğŸ’­

2. **Build & Install** ğŸ”§âš™ï¸  
   ```
   make tool
   ```
   This will build the HeLLM tool and install it to `/usr/local/bin`. ğŸ“âœ…

### Step 3: Install the VSCode/Cursor Extension ğŸ§©ğŸ’»

Choose one of the following methods:

#### Option A: Download .vsix File (Works with Binary Download) ğŸ“¥

1. Download `hellm-extension.vsix` from the [releases page](https://github.com/JoshPattman/hellm/releases) ğŸ“‚
2. Install in your editor: âš™ï¸
   - Open Command Palette (`Ctrl+Shift+P` / `Cmd+Shift+P`)
   - Run "Extensions: Install from VSIX..."
   - Select the downloaded `hellm-extension.vsix` file ğŸ¯

#### Option B: Build Extension (When Building from Source) ğŸ”¨

```
make extension
```
This will copy the extension to your VSCode and Cursor extensions folders. ğŸ“‚ğŸ¯

---

That's it! ğŸ‰ You're ready to write the most exciting and expensive code of your life! ğŸ’°ğŸ”¥ If you need to see the subcommands of hellm, run `hellm help`. ğŸ“–â“
